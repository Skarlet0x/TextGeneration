{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYsY/9VjtqNZPP8pMpdnv7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTS"
      ],
      "metadata": {
        "id": "FKqFu3gG9tKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "JVPgrNNPhW02"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = open(\"corpus.txt\", \"r\", encoding = \"utf-8-sig\").read()"
      ],
      "metadata": {
        "id": "VbUaw8ubhmh-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UMXoAzbCmWat",
        "outputId": "d559bc35-0cb6-457f-b6a5-7a5289f841bd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the Devoid of Sorrow\\nThe Air and my Heart full of Luster\\nBehind the Mountains\\nThere must be a key'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREPROCESSING"
      ],
      "metadata": {
        "id": "pIa1B6h5iOn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preserves the \\n character, unlike the regular .split()\n",
        "tokens = re.findall(r\"\\S+|\\n\", dataset)"
      ],
      "metadata": {
        "id": "BYOcMQ_JmjMj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:10]"
      ],
      "metadata": {
        "id": "nqTSI9-VmlKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f56935da-f773-4bb5-8362-783053079bed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In', 'the', 'Devoid', 'of', 'Sorrow', '\\n', 'The', 'Air', 'and', 'my']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # punctuation, except: \n",
        "    # ' - because of 'cause and fuckin'\n",
        "    # & - because of and\n",
        "    # \\n\n",
        "    text = re.sub(r\"[^\\n&a-zA-Z']\", \" \", text)\n",
        "\n",
        "    # lower-case\n",
        "    text = text.lower()\n",
        "\n",
        "    # clean archaisms and other special cases\n",
        "    text = re.sub(r\"'cause \", \"because\", text)\n",
        "    text = re.sub(r\"shalt\", \"shall\", text)\n",
        "    text = re.sub(r\"kaos\", \"chaos\", text)\n",
        "    text = re.sub(r\"'till\", \"until\", text)\n",
        "    text = re.sub(r\"fuckin'\", \"fucking\", text)\n",
        "    text = re.sub(r\"couldst\", \"could\", text)\n",
        "    text = re.sub(r\"sayeth\", \"says\", text)\n",
        "    text = re.sub(r\"calleth\", \"calls\", text)\n",
        "    text = re.sub(r\"&\", \" and \", text)\n",
        "    text = re.sub(r\"sathan\", \"satan\", text)\n",
        "    text = re.sub(r\"'em\", \"them\", text)\n",
        "\n",
        "    # possible parts of other words\n",
        "    text = re.sub(r\"(?<![a-zA-Z])thy(?![a-zA-Z])|thine\", \"your\", text)\n",
        "    text = re.sub(r\"thou|thee|(?<![a-zA-Z])ye(?![a-zA-Z])\", \"you\", text)\n",
        "    text = re.sub(r\"(?<![a-zA-Z])o(?![a-zA-Z])\", \"oh\", text)\n",
        "    text = re.sub(r\"(?<![a-zA-Z])tis(?![a-zA-Z])\", \"it is\", text)\n",
        "    text = re.sub(r\"(?<![a-zA-Z])thru(?![a-zA-Z])\", \"through\", text)\n",
        "    text = re.sub(r\"(?<![a-zA-Z])ov(?![a-zA-Z])\", \"of\", text)\n",
        "    text = re.sub(r\"(?<![a-zA-Z])hast(?![a-zA-Z])\", \"have\", text)\n",
        "\n",
        "    # double whitespaces\n",
        "    text = re.sub(r\" +\", \" \", text)\n",
        "  \n",
        "    return text"
      ],
      "metadata": {
        "id": "MCi70KwYl1Q0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = [clean_text(token) for token in tokens]"
      ],
      "metadata": {
        "id": "3CYOII6DkWns"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:10]"
      ],
      "metadata": {
        "id": "3q0SiO4AlWm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7682ed9c-e421-4a92-838f-9fd7c7a59613"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in', 'the', 'devoid', 'of', 'sorrow', '\\n', 'the', 'air', 'and', 'my']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EXPLORATORY DATA ANALYSIS"
      ],
      "metadata": {
        "id": "A5YAehfPnJzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# total tokens\n",
        "len(text)"
      ],
      "metadata": {
        "id": "eAJ1yvjQnORL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f60a8c-8a13-4831-af20-429acb2931b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "390866"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unique tokens\n",
        "len(set(text))"
      ],
      "metadata": {
        "id": "RaEZRzvanRWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fd2b43-e3eb-4141-db39-80af75cbd382"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21491"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hapax legomena - outliers - possibly remove?"
      ],
      "metadata": {
        "id": "z-2FLMhZtLeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab analysis - lemmatize"
      ],
      "metadata": {
        "id": "xN1s12ZEe1dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SEQUENCES"
      ],
      "metadata": {
        "id": "t-IJfw8xj7T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 50\n",
        "X_items = []\n",
        "y = []\n",
        "\n",
        "for i in range(0, len(tokens)-seq_len):\n",
        "\tX_items.append(tokens[i:i+seq_len])\n",
        "\ty.append(tokens[i+seq_len])"
      ],
      "metadata": {
        "id": "vigKecggiMiG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = [\" \".join(item) for item in X_items]"
      ],
      "metadata": {
        "id": "aYrD5rpil1wu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf-LYb1SOKka",
        "outputId": "f84ec733-0903-425e-afa7-026dd9fd9bb7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In the Devoid of Sorrow \\n The Air and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you',\n",
              " 'the Devoid of Sorrow \\n The Air and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away',\n",
              " 'Devoid of Sorrow \\n The Air and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away \\n',\n",
              " 'of Sorrow \\n The Air and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away \\n Two',\n",
              " 'Sorrow \\n The Air and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away \\n Two Shades',\n",
              " '\\n The Air and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away \\n Two Shades of',\n",
              " 'The Air and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away \\n Two Shades of the',\n",
              " 'Air and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away \\n Two Shades of the Midnight',\n",
              " 'and my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away \\n Two Shades of the Midnight Fire',\n",
              " 'my Heart full of Luster \\n Behind the Mountains \\n There must be a key to the Gates \\n Right passed easy Talk \\n We can once again walk the Path of Sorrow \\n Let the Turn of Search bring you away \\n Two Shades of the Midnight Fire \\n']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrw4WO1JvFts",
        "outputId": "8890bf73-c9d6-4f14-9b2e-3322b34e9e57"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['away', '\\n', 'Two', 'Shades', 'of', 'the', 'Midnight', 'Fire', '\\n', 'In']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING THE DIMENSIONS"
      ],
      "metadata": {
        "id": "I0NslwfFk9gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = [re.findall(r\"\\S+|\\n\", sequence) for sequence in X]"
      ],
      "metadata": {
        "id": "xtcp00C2heYT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_x = [len(item) for item in x_test]"
      ],
      "metadata": {
        "id": "j8_uutHDhkjj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_x[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgCC8uLdhxSL",
        "outputId": "14d6eebb-239f-48b9-a515-2c49fe2a7202"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50, 50, 50, 50, 50, 50, 50, 50, 50, 50]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(lengths_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FFulpKchsdL",
        "outputId": "b752540b-1bf7-4e43-b330-a2035ee0f995"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = [re.findall(r\"\\S+|\\n\", sequence) for sequence in y]"
      ],
      "metadata": {
        "id": "zwOF7VFoxhRn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_y = [len(item) for item in y_test]"
      ],
      "metadata": {
        "id": "xcNX0NgXxj83"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyPQOVRGxl3v",
        "outputId": "ebd0858f-2afb-412a-f699-51cab2d2b4fa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(lengths_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh8LHkSLxnaA",
        "outputId": "d8606278-7a27-44e5-af57-2b0463b34eff"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TOKENIZATION"
      ],
      "metadata": {
        "id": "C73Ou5QQlBlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# to keep the \\n\n",
        "filters_ = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t' \n",
        "tokenizer = Tokenizer(filters=filters_)\n",
        "\n",
        "tokenizer.fit_on_texts(X)"
      ],
      "metadata": {
        "id": "eo3T0ETW9OPI"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_emb = tokenizer.texts_to_sequences(X)\n",
        "y_emb = tokenizer.texts_to_sequences(y)"
      ],
      "metadata": {
        "id": "0GoEBiWxrSkI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING THE DIMENSIONS\n",
        "# WHYYYYYYY"
      ],
      "metadata": {
        "id": "gpa3yztMzKdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_X_emb = [len(item) for item in X_emb]"
      ],
      "metadata": {
        "id": "BAiPdSwMyo6u"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(lengths_X_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-bBmzR7yuKG",
        "outputId": "d750ad26-871c-4758-fb49-4bd557d6006b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{46, 47, 48, 49, 50, 51, 52, 53, 54, 55}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lengths_y_emb = [len(item) for item in y_emb]"
      ],
      "metadata": {
        "id": "68TQhKUmyl12"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set(lengths_y_emb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K43cpTivyxvO",
        "outputId": "3e5fd6e0-c517-469b-9545-b66308da8ccd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "\n",
        "y_categorical = to_categorical(y_emb, num_classes=vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "sTBTbCOTt7m2",
        "outputId": "dfa3755a-5d46-4fc6-cbaa-95f248c4fca9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-0fad86e87728>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (390816,) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL"
      ],
      "metadata": {
        "id": "eGa5IgHNiSLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Embedding, LSTM, Dense, Dropout"
      ],
      "metadata": {
        "id": "y4ca6khquEjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = seq_len\n",
        "VOCABULARY_SIZE = len(tokenizer.word_index)\n",
        "EMBEDDING_DIMENSION = 50\n",
        "LSTM_UNITS = 50\n",
        "DROPOUT_RATE = 0.2"
      ],
      "metadata": {
        "id": "-DGk5w32uO0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn = Sequential()\n",
        "\n",
        "rnn.add(Input(INPUT_SHAPE,))\n",
        "# +1 here resolves the indexing problem during training\n",
        "rnn.add(Embedding(VOCABULARY_SIZE+1, EMBEDDING_DIMENSION))\n",
        "rnn.add(LSTM(LSTM_UNITS, return_sequences=True))\n",
        "rnn.add(Dense(VOCABULARY_SIZE, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "571HSDYJeods"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "GilsCwQceosi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClIhRRUvvWSB",
        "outputId": "c99548df-8204-4002-8db0-d1dd033449d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 50, 50)            886750    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50, 50)            20200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50, 17734)         904434    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,811,384\n",
            "Trainable params: 1,811,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MODEL TRAINING"
      ],
      "metadata": {
        "id": "VESfj6AVjYus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TzcfbFB1vW4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GENERATION"
      ],
      "metadata": {
        "id": "FvEXsjvu-HVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FQwsMcT1epCK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}